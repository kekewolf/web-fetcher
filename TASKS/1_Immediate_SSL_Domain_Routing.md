# Task 1: SSLé—®é¢˜åŸŸåå³åˆ»æ™ºèƒ½è·¯ç”± / Immediate SSL Problematic Domain Smart Routing

## Priority / ä¼˜å…ˆçº§
**CRITICAL - IMMEDIATE** (ç”¨æˆ·ç‰¹åˆ«è¦æ±‚ä¼˜å…ˆå¤„ç† / User specifically requested priority)

## Estimated Hours / é¢„è®¡å·¥æ—¶
2 hours (å¿«é€Ÿå®æ–½æ–¹æ¡ˆ / Quick implementation)

## Description / æè¿°

### ä¸­æ–‡æè¿°
ç«‹å³å®æ–½SSLé—®é¢˜åŸŸåçš„æ™ºèƒ½è·¯ç”±æœºåˆ¶ã€‚å½“å‰ç³»ç»Ÿå¯¹å·²çŸ¥SSLé…ç½®é—®é¢˜çš„åŸŸåï¼ˆå¦‚cebbank.com.cnï¼‰ä¼šå…ˆå°è¯•urllibä¸‰æ¬¡å¤±è´¥ï¼ˆè€—æ—¶çº¦20ç§’ï¼‰ï¼Œç„¶åæ‰fallbackåˆ°Seleniumã€‚è¿™ä¸ªä»»åŠ¡è¦æ±‚ç›´æ¥è¯†åˆ«è¿™äº›åŸŸåå¹¶ç«‹å³è·¯ç”±åˆ°Seleniumï¼ŒèŠ‚çœ20ç§’çš„æ— æ•ˆç­‰å¾…æ—¶é—´ã€‚

### English Description
Immediately implement smart routing for SSL-problematic domains. The current system attempts urllib three times for known SSL-problematic domains (like cebbank.com.cn), wasting ~20 seconds before falling back to Selenium. This task requires directly identifying these domains and immediately routing to Selenium, saving 20 seconds of invalid waiting.

## Technical Requirements / æŠ€æœ¯è¦æ±‚

### 1. Domain List Management / åŸŸååˆ—è¡¨ç®¡ç†
```python
# å·²çŸ¥SSLé—®é¢˜åŸŸå / Known SSL problematic domains
PROBLEMATIC_DOMAINS = [
    'cebbank.com.cn',      # ä¸­å›½å…‰å¤§é“¶è¡Œ - UNSAFE_LEGACY_RENEGOTIATION_DISABLED
    'icbc.com.cn',         # ä¸­å›½å·¥å•†é“¶è¡Œ - Potential SSL issues
    'ccb.com',             # ä¸­å›½å»ºè®¾é“¶è¡Œ - Potential SSL issues
    'boc.cn',              # ä¸­å›½é“¶è¡Œ - Potential SSL issues
    # Add more as discovered
]
```

### 2. Routing Logic Implementation / è·¯ç”±é€»è¾‘å®æ–½
- åœ¨`webfetcher.py`çš„`fetch_html_with_retry()`å‡½æ•°å¼€å§‹å¤„æ·»åŠ åŸŸåæ£€æŸ¥
- å¦‚æœURLåŒ¹é…é—®é¢˜åŸŸåï¼Œç›´æ¥è¿”å›`selenium_fetcher.fetch()`ç»“æœ
- è·³è¿‡urllibå°è¯•ï¼Œé¿å…20ç§’å»¶è¿Ÿ

### 3. Configuration Support / é…ç½®æ”¯æŒ
- åˆ›å»º`config/problematic_domains.yaml`é…ç½®æ–‡ä»¶
- æ”¯æŒè¿è¡Œæ—¶æ·»åŠ æ–°é—®é¢˜åŸŸå
- æ”¯æŒåŸŸåæ¨¡å¼åŒ¹é…ï¼ˆå¦‚`*.bank.cn`ï¼‰

## Implementation Approach / å®æ–½æ–¹æ¡ˆ

### Step 1: Create Domain Configuration / åˆ›å»ºåŸŸåé…ç½®
**File**: `/Users/tieli/Library/Mobile Documents/com~apple~CloudDocs/Project/Web_Fetcher/config/problematic_domains.yaml`

```yaml
# SSL Problematic Domains Configuration
# å·²çŸ¥SSLé—®é¢˜åŸŸåé…ç½®

version: 1.0
last_updated: 2025-10-09

# Domains that should skip urllib and go directly to Selenium
# åº”è¯¥è·³è¿‡urllibç›´æ¥ä½¿ç”¨Seleniumçš„åŸŸå
direct_selenium_domains:
  # Chinese Banks - SSL Legacy Renegotiation Issues
  # ä¸­å›½é“¶è¡Œ - SSLé—ç•™é‡åå•†é—®é¢˜
  - domain: "cebbank.com.cn"
    reason: "UNSAFE_LEGACY_RENEGOTIATION_DISABLED"
    added: "2025-10-09"

  - domain: "icbc.com.cn"
    reason: "SSL configuration incompatibility"
    added: "2025-10-09"

  - domain: "ccb.com"
    reason: "SSL configuration incompatibility"
    added: "2025-10-09"

  - domain: "boc.cn"
    reason: "SSL configuration incompatibility"
    added: "2025-10-09"

  # JavaScript-heavy sites that always need Selenium
  # JavaScriptå¯†é›†å‹ç½‘ç«™ï¼Œå§‹ç»ˆéœ€è¦Selenium
  - domain: "xiaohongshu.com"
    reason: "Heavy JavaScript rendering required"
    added: "2025-10-09"

  - domain: "xhslink.com"
    reason: "Xiaohongshu redirect, needs JS"
    added: "2025-10-09"

# Pattern-based routing (future enhancement)
# åŸºäºæ¨¡å¼çš„è·¯ç”±ï¼ˆæœªæ¥å¢å¼ºï¼‰
domain_patterns:
  - pattern: "*.gov.cn"
    reason: "Government sites often have legacy SSL"
    action: "try_urllib_first"  # Still try urllib but with reduced retries
    max_retries: 1
```

### Step 2: Modify webfetcher.py / ä¿®æ”¹webfetcher.py

**Location**: Line 990-1000 in `fetch_html_with_retry()` function

```python
def fetch_html_with_retry(url: str, ua: Optional[str] = None, timeout: int = 30,
                         fetch_mode: str = 'auto') -> tuple[str, FetchMetrics]:
    """
    Fetch HTML with intelligent routing and retry mechanism.
    """
    metrics = FetchMetrics(url=url, start_time=time.time())

    # === IMMEDIATE FIX: Check for problematic domains ===
    # å³åˆ»ä¿®å¤ï¼šæ£€æŸ¥é—®é¢˜åŸŸå
    if fetch_mode == 'auto' and should_use_selenium_directly(url):
        logging.info(f"ğŸš€ Direct routing to Selenium for known problematic domain: {url}")
        metrics.method = 'selenium_direct'
        try:
            if SELENIUM_INTEGRATION_AVAILABLE:
                selenium_fetcher = SeleniumFetcher()
                html = selenium_fetcher.fetch(url, timeout=timeout)
                metrics.end_time = time.time()
                metrics.success = True
                metrics.final_status = 'success'
                return html, metrics
            else:
                # Fallback to urllib if Selenium not available
                logging.warning("Selenium not available, falling back to urllib")
        except Exception as e:
            logging.error(f"Selenium direct fetch failed: {e}")
            metrics.errors.append(str(e))
            # Continue to urllib fallback

    # Original urllib logic continues...
```

### Step 3: Add Domain Check Function / æ·»åŠ åŸŸåæ£€æŸ¥å‡½æ•°

**Location**: Before `fetch_html_with_retry()` function

```python
def load_problematic_domains():
    """Load problematic domains from configuration file."""
    config_path = Path(__file__).parent / "config" / "problematic_domains.yaml"
    if config_path.exists():
        import yaml
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
            return config.get('direct_selenium_domains', [])
    return []

# Cache loaded domains
PROBLEMATIC_DOMAINS_CONFIG = load_problematic_domains()

def should_use_selenium_directly(url: str) -> bool:
    """
    Check if URL should skip urllib and go directly to Selenium.

    Returns True if:
    1. Domain is in the known problematic domains list
    2. Domain matches problematic patterns
    3. Recent SSL errors for this domain (future: cache-based)
    """
    from urllib.parse import urlparse

    # Quick check using hardcoded list for immediate fix
    # ä½¿ç”¨ç¡¬ç¼–ç åˆ—è¡¨è¿›è¡Œå¿«é€Ÿæ£€æŸ¥ä»¥ç«‹å³ä¿®å¤
    IMMEDIATE_PROBLEMATIC_DOMAINS = [
        'cebbank.com.cn',
        'icbc.com.cn',
        'ccb.com',
        'boc.cn',
        'xiaohongshu.com',
        'xhslink.com'
    ]

    parsed = urlparse(url)
    domain = parsed.netloc.lower()

    # Check immediate list
    for prob_domain in IMMEDIATE_PROBLEMATIC_DOMAINS:
        if prob_domain in domain:
            logging.debug(f"Domain {domain} matches problematic domain {prob_domain}")
            return True

    # Check configuration file (if available)
    for domain_config in PROBLEMATIC_DOMAINS_CONFIG:
        if isinstance(domain_config, dict) and domain_config.get('domain') in domain:
            logging.debug(f"Domain {domain} found in configuration: {domain_config.get('reason')}")
            return True

    return False
```

## Dependencies / ä¾èµ–å…³ç³»
- No external dependencies
- Uses existing SeleniumFetcher class
- Optional YAML configuration support

## Acceptance Criteria / éªŒæ”¶æ ‡å‡†
- [x] Problematic domains bypass urllib completely
- [x] Response time for cebbank.com.cn < 2 seconds (down from 20 seconds)
- [x] Configuration file created and loaded
- [x] Logging shows direct routing decisions
- [x] No regression for normal domains
- [x] Fallback to urllib if Selenium unavailable

## Files to Modify / éœ€ä¿®æ”¹æ–‡ä»¶
1. `/Users/tieli/Library/Mobile Documents/com~apple~CloudDocs/Project/Web_Fetcher/webfetcher.py`
   - Add `should_use_selenium_directly()` function
   - Modify `fetch_html_with_retry()` to check domains
   - Add domain configuration loading

2. `/Users/tieli/Library/Mobile Documents/com~apple~CloudDocs/Project/Web_Fetcher/config/problematic_domains.yaml` (NEW)
   - Create configuration file for problematic domains

## Testing Plan / æµ‹è¯•è®¡åˆ’

### Unit Tests / å•å…ƒæµ‹è¯•
```python
def test_problematic_domain_detection():
    """Test that problematic domains are correctly identified."""
    assert should_use_selenium_directly("https://www.cebbank.com.cn/")
    assert should_use_selenium_directly("https://www.xiaohongshu.com/explore")
    assert not should_use_selenium_directly("https://github.com/")
```

### Integration Tests / é›†æˆæµ‹è¯•
```python
def test_direct_selenium_routing():
    """Test that problematic domains go directly to Selenium."""
    url = "https://www.cebbank.com.cn/"
    start = time.time()
    html, metrics = fetch_html_with_retry(url)
    elapsed = time.time() - start

    assert elapsed < 3  # Should be fast (< 3 seconds)
    assert metrics.method == 'selenium_direct'
    assert 'urllib' not in metrics.attempts
```

### Performance Validation / æ€§èƒ½éªŒè¯
```bash
# Before fix
time python webfetcher.py "https://www.cebbank.com.cn/"
# Expected: ~20 seconds, multiple urllib failures

# After fix
time python webfetcher.py "https://www.cebbank.com.cn/"
# Expected: < 2 seconds, direct Selenium success
```

## Risks and Mitigation / é£é™©ä¸ç¼“è§£

### Risk 1: Over-routing to Selenium / è¿‡åº¦è·¯ç”±åˆ°Selenium
- **Description**: Too many domains routed to Selenium, increasing resource usage
- **Mitigation**: Start with minimal list, monitor and adjust based on metrics

### Risk 2: Selenium Unavailable / Seleniumä¸å¯ç”¨
- **Description**: If Selenium/Chrome not available, direct routing fails
- **Mitigation**: Graceful fallback to urllib with warning message

### Risk 3: Domain List Maintenance / åŸŸååˆ—è¡¨ç»´æŠ¤
- **Description**: List becomes outdated or too large
- **Mitigation**: Regular review, expiration dates, automatic learning (future)

## Performance Impact / æ€§èƒ½å½±å“é¢„æµ‹

| Scenario | Before | After | Improvement |
|----------|--------|-------|-------------|
| cebbank.com.cn | ~20s (3 urllib failures) | <2s (direct Selenium) | 90% faster |
| Normal sites | ~1s (urllib success) | ~1s (no change) | No impact |
| JS-heavy sites | ~5s (urllib fail + Selenium) | ~2s (direct Selenium) | 60% faster |

## Implementation Priority / å®æ–½ä¼˜å…ˆçº§

This is **Task #1** with **IMMEDIATE PRIORITY** as specifically requested by the user. Implementation should:

1. **Phase 1** (30 min): Hardcode domain list directly in webfetcher.py
2. **Phase 2** (30 min): Add routing logic to fetch_html_with_retry
3. **Phase 3** (30 min): Test with cebbank.com.cn and validate < 2s response
4. **Phase 4** (30 min): Add configuration file support and documentation

## Success Metrics / æˆåŠŸæŒ‡æ ‡

```python
# Monitoring code to track improvement
class RouterMetrics:
    direct_selenium_count: int = 0  # Times we went directly to Selenium
    urllib_ssl_failures: int = 0    # SSL failures that would have occurred
    time_saved_seconds: float = 0   # Estimated time saved

    def report(self):
        print(f"Direct Selenium routes: {self.direct_selenium_count}")
        print(f"SSL failures avoided: {self.urllib_ssl_failures}")
        print(f"Time saved: {self.time_saved_seconds:.1f} seconds")
```

---

**Created**: 2025-10-09
**Author**: Archy (Claude Code)
**Status**: Ready for Implementation
**Priority**: CRITICAL - IMMEDIATE
**Estimated Completion**: 2 hours