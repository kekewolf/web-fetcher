# Web_Fetcher

A powerful and intelligent web content extraction tool with multi-mode crawling capabilities and smart URL parsing.

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„æ™ºèƒ½ç½‘ç»œå†…å®¹æå–å·¥å…·ï¼Œå…·å¤‡å¤šæ¨¡å¼çˆ¬å–èƒ½åŠ›å’Œæ™ºèƒ½URLè§£æåŠŸèƒ½ã€‚

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

## English

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd Web_Fetcher

# Install dependencies
pip install -r requirements.txt

# Make the script executable (optional)
chmod +x wf.py
```

### Quick Start

```bash
# Basic usage - extract content from a URL
wf https://example.com

# Extract URL from mixed text (Chinese/English)
wf "Check this article çœ‹è¿™ç¯‡æ–‡ç«  http://example.com/article"

# Fast mode - quick content extraction
wf fast https://example.com

# Full mode - comprehensive extraction
wf full https://example.com

# Site mode - crawl entire website
wf site https://example.com

# Raw mode - get original HTML
wf raw https://example.com
```

### Features

#### ğŸ¯ Smart URL Extraction
Automatically extracts URLs from mixed language text, supporting various platforms including WeChat articles and Xiaohongshu posts.

#### ğŸš€ Multiple Crawling Modes
- **Single Page**: Default mode for single page content
- **Fast Mode**: Quick extraction with minimal processing
- **Full Mode**: Comprehensive content extraction
- **Site Mode**: Complete website crawling
- **Raw Mode**: Original HTML without processing

#### ğŸŒ Platform Support
- WeChat Articles (with JavaScript filtering)
- Xiaohongshu (with image extraction)
- Hugo/Jekyll static sites
- General web pages

#### ğŸ“¸ Image Handling
```bash
# Default - show image URLs only
wf https://example.com

# Download images
wf https://example.com --download-assets

# Legacy compatibility mode
WF_LEGACY_IMAGE_MODE=1 wf https://example.com
```

#### ğŸ“ Output Control
```bash
# Custom output directory
wf https://example.com -o ./my-output

# Verbose logging
wf https://example.com --verbose

# Raw HTML output
wf https://example.com --raw
```

### Common Use Cases

#### Extract WeChat Article
```bash
wf "https://mp.weixin.qq.com/s/<article-id>"
```

#### Crawl Documentation Site
```bash
wf site https://example.com -o ./docs-backup
```

#### Quick Content Check
```bash
wf fast https://example.com/latest
```

#### Download Article with Images
```bash
wf https://example.com/post --download-assets
```

### Advanced Usage

#### Environment Variables
```bash
# Enable legacy image mode
export WF_LEGACY_IMAGE_MODE=1

# Set default output directory
export WF_OUTPUT_DIR=/path/to/output
```

#### Batch Processing
```bash
# Process multiple URLs from a file
while IFS= read -r url; do
    wf "$url" -o ./batch-output
done < urls.txt
```

### Requirements

- Python 3.7+
- BeautifulSoup4
- Requests
- Other dependencies listed in requirements.txt

### Error Handling

The tool includes:
- Automatic retry mechanism for failed requests
- Intelligent content extraction fallbacks
- Comprehensive error logging with `--verbose` flag

---

## ä¸­æ–‡

### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone <repository-url>
cd Web_Fetcher

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è®¾ç½®è„šæœ¬å¯æ‰§è¡Œæƒé™ï¼ˆå¯é€‰ï¼‰
chmod +x wf.py
```

### å¿«é€Ÿå¼€å§‹

```bash
# åŸºç¡€ç”¨æ³• - ä»URLæå–å†…å®¹
wf https://example.com

# ä»æ··åˆæ–‡æœ¬ä¸­æå–URLï¼ˆä¸­è‹±æ–‡ï¼‰
wf "æŸ¥çœ‹è¿™ç¯‡æ–‡ç«  Check this article http://example.com/article"

# å¿«é€Ÿæ¨¡å¼ - å¿«é€Ÿå†…å®¹æå–
wf fast https://example.com

# å®Œæ•´æ¨¡å¼ - å…¨é¢å†…å®¹æå–
wf full https://example.com

# ç«™ç‚¹æ¨¡å¼ - çˆ¬å–æ•´ä¸ªç½‘ç«™
wf site https://example.com

# åŸå§‹æ¨¡å¼ - è·å–åŸå§‹HTML
wf raw https://example.com
```

### åŠŸèƒ½ç‰¹æ€§

#### ğŸ¯ æ™ºèƒ½URLæå–
è‡ªåŠ¨ä»æ··åˆè¯­è¨€æ–‡æœ¬ä¸­æå–URLï¼Œæ”¯æŒå¾®ä¿¡æ–‡ç« ã€å°çº¢ä¹¦ç­‰å¤šç§å¹³å°ã€‚

#### ğŸš€ å¤šç§çˆ¬å–æ¨¡å¼
- **å•é¡µæ¨¡å¼**: é»˜è®¤æ¨¡å¼ï¼Œç”¨äºå•é¡µå†…å®¹æå–
- **å¿«é€Ÿæ¨¡å¼**: å¿«é€Ÿæå–ï¼Œæœ€å°‘å¤„ç†
- **å®Œæ•´æ¨¡å¼**: å…¨é¢å†…å®¹æå–
- **ç«™ç‚¹æ¨¡å¼**: å®Œæ•´ç½‘ç«™çˆ¬å–
- **åŸå§‹æ¨¡å¼**: ä¸å¤„ç†çš„åŸå§‹HTML

#### ğŸŒ å¹³å°æ”¯æŒ
- å¾®ä¿¡å…¬ä¼—å·æ–‡ç« ï¼ˆè¿‡æ»¤JavaScriptä»£ç ï¼‰
- å°çº¢ä¹¦å†…å®¹ï¼ˆæ”¯æŒå›¾ç‰‡æå–ï¼‰
- Hugo/Jekyllé™æ€ç½‘ç«™
- é€šç”¨ç½‘é¡µ

#### ğŸ“¸ å›¾ç‰‡å¤„ç†
```bash
# é»˜è®¤ - ä»…æ˜¾ç¤ºå›¾ç‰‡URL
wf https://example.com

# ä¸‹è½½å›¾ç‰‡
wf https://example.com --download-assets

# å…¼å®¹æ¨¡å¼
WF_LEGACY_IMAGE_MODE=1 wf https://example.com
```

#### ğŸ“ è¾“å‡ºæ§åˆ¶
```bash
# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
wf https://example.com -o ./my-output

# è¯¦ç»†æ—¥å¿—
wf https://example.com --verbose

# åŸå§‹HTMLè¾“å‡º
wf https://example.com --raw
```

### å¸¸ç”¨åœºæ™¯

#### æå–å¾®ä¿¡æ–‡ç« 
```bash
wf "https://mp.weixin.qq.com/s/<article-id>"
```

#### çˆ¬å–æ–‡æ¡£ç½‘ç«™
```bash
wf site https://example.com -o ./docs-backup
```

#### å¿«é€Ÿå†…å®¹æ£€æŸ¥
```bash
wf fast https://example.com/latest
```

#### ä¸‹è½½æ–‡ç« åŠå›¾ç‰‡
```bash
wf https://example.com/post --download-assets
```

#### å¤„ç†å°çº¢ä¹¦é“¾æ¥
```bash
wf "ä¸æ˜¯åŠå…¬70% çš„äººç”¨ ChatGPT å±…ç„¶æ˜¯ä¸ºäº†ï¼Ÿ http://xhslink.com/<link-id> å¤åˆ¶åæ‰“å¼€ã€å°çº¢ä¹¦ã€‘"
```

### é«˜çº§ç”¨æ³•

#### ç¯å¢ƒå˜é‡
```bash
# å¯ç”¨å…¼å®¹å›¾ç‰‡æ¨¡å¼
export WF_LEGACY_IMAGE_MODE=1

# è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
export WF_OUTPUT_DIR=/path/to/output
```

#### æ‰¹é‡å¤„ç†
```bash
# ä»æ–‡ä»¶ä¸­æ‰¹é‡å¤„ç†å¤šä¸ªURL
while IFS= read -r url; do
    wf "$url" -o ./batch-output
done < urls.txt
```

### ç³»ç»Ÿè¦æ±‚

- Python 3.7+
- BeautifulSoup4
- Requests
- å…¶ä»–ä¾èµ–è§ requirements.txt

### é”™è¯¯å¤„ç†

å·¥å…·åŒ…å«ï¼š
- å¤±è´¥è¯·æ±‚çš„è‡ªåŠ¨é‡è¯•æœºåˆ¶
- æ™ºèƒ½å†…å®¹æå–é™çº§ç­–ç•¥
- ä½¿ç”¨ `--verbose` æ ‡å¿—çš„å…¨é¢é”™è¯¯æ—¥å¿—

### æŠ€æœ¯ç‰¹æ€§

- æ”¯æŒå¸¦å¼•å·å’Œä¸å¸¦å¼•å·çš„HTMLé“¾æ¥
- æ™ºèƒ½å†…å®¹æå–ï¼Œæ”¯æŒç°ä»£ç½‘ç«™æ¶æ„
- å…¨é¢çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- æ€§èƒ½ä¼˜åŒ–çš„çˆ¬å–ç®—æ³•

---

## Contributing | è´¡çŒ®

Contributions are welcome! Please feel free to submit a Pull Request.

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤Pull Requestã€‚

## License | è®¸å¯è¯

[Your License Here]

## Support | æ”¯æŒ

For issues and questions, please open an issue on GitHub.

å¦‚æœ‰é—®é¢˜å’Œç–‘é—®ï¼Œè¯·åœ¨GitHubä¸Šå¼€issueã€‚